{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-24T10:23:04.798002Z","iopub.execute_input":"2021-10-24T10:23:04.798399Z","iopub.status.idle":"2021-10-24T10:23:05.312717Z","shell.execute_reply.started":"2021-10-24T10:23:04.798278Z","shell.execute_reply":"2021-10-24T10:23:05.312174Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom datetime import datetime","metadata":{"execution":{"iopub.status.busy":"2021-10-24T10:23:05.314220Z","iopub.execute_input":"2021-10-24T10:23:05.314492Z","iopub.status.idle":"2021-10-24T10:23:07.080025Z","shell.execute_reply.started":"2021-10-24T10:23:05.314446Z","shell.execute_reply":"2021-10-24T10:23:07.079011Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"X=transforms.Compose([transforms.ToTensor(),transforms.Resize((32,32))])\n","metadata":{"execution":{"iopub.status.busy":"2021-10-24T10:23:07.081673Z","iopub.execute_input":"2021-10-24T10:23:07.082076Z","iopub.status.idle":"2021-10-24T10:23:07.087271Z","shell.execute_reply.started":"2021-10-24T10:23:07.082038Z","shell.execute_reply":"2021-10-24T10:23:07.086002Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"Batch_size = 128\n\ndataset =torchvision.datasets.ImageFolder('../input/covid-face-mask-detection-dataset', transform=X)\ntrain_dataset=torchvision.datasets.ImageFolder('../input/covid-face-mask-detection-dataset/New Masks Dataset/Train' , transform=X)\ntest_dataset=torchvision.datasets.ImageFolder('../input/covid-face-mask-detection-dataset/New Masks Dataset/Test' , transform=X)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-24T10:23:07.091394Z","iopub.execute_input":"2021-10-24T10:23:07.091658Z","iopub.status.idle":"2021-10-24T10:23:07.125793Z","shell.execute_reply.started":"2021-10-24T10:23:07.091631Z","shell.execute_reply":"2021-10-24T10:23:07.124037Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_dataloader=torch.utils.data.DataLoader(train_dataset , batch_size=Batch_size , shuffle=True )\ntest_dataloader=torch.utils.data.DataLoader(test_dataset , batch_size=Batch_size , shuffle=True )\n","metadata":{"execution":{"iopub.status.busy":"2021-10-24T10:23:07.129653Z","iopub.execute_input":"2021-10-24T10:23:07.130229Z","iopub.status.idle":"2021-10-24T10:23:07.139129Z","shell.execute_reply.started":"2021-10-24T10:23:07.130191Z","shell.execute_reply":"2021-10-24T10:23:07.138291Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"K = 2","metadata":{"execution":{"iopub.status.busy":"2021-10-24T10:23:07.143439Z","iopub.execute_input":"2021-10-24T10:23:07.146089Z","iopub.status.idle":"2021-10-24T10:23:07.151347Z","shell.execute_reply.started":"2021-10-24T10:23:07.146051Z","shell.execute_reply":"2021-10-24T10:23:07.150500Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n  def __init__(self, K):\n    super(CNN, self).__init__()\n    self.conv_layers = nn.Sequential(\n      nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=2 ),\n      nn.ReLU(),\n      nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2 ),\n      nn.ReLU(),\n      nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2 ),\n      nn.ReLU()\n    )\n    self.dense_layers = nn.Sequential(\n      nn.Dropout(0.2),\n      nn.Linear(128 * 3 * 3, 512),\n      nn.ReLU(),\n      nn.Dropout(0.2),\n      nn.Linear(512, K)\n    )\n  \n  def forward(self, X):\n    out = self.conv_layers(X)\n    out = out.view(out.size(0), -1)\n    out = self.dense_layers(out)\n    return out\n","metadata":{"execution":{"iopub.status.busy":"2021-10-24T10:23:07.155801Z","iopub.execute_input":"2021-10-24T10:23:07.156594Z","iopub.status.idle":"2021-10-24T10:23:07.167687Z","shell.execute_reply.started":"2021-10-24T10:23:07.156540Z","shell.execute_reply":"2021-10-24T10:23:07.166761Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = CNN(K)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T10:23:07.168946Z","iopub.execute_input":"2021-10-24T10:23:07.169586Z","iopub.status.idle":"2021-10-24T10:23:07.215002Z","shell.execute_reply.started":"2021-10-24T10:23:07.169550Z","shell.execute_reply":"2021-10-24T10:23:07.214396Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T10:23:07.216090Z","iopub.execute_input":"2021-10-24T10:23:07.216553Z","iopub.status.idle":"2021-10-24T10:23:10.137377Z","shell.execute_reply.started":"2021-10-24T10:23:07.216519Z","shell.execute_reply":"2021-10-24T10:23:10.136674Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters())","metadata":{"execution":{"iopub.status.busy":"2021-10-24T10:23:10.140020Z","iopub.execute_input":"2021-10-24T10:23:10.140491Z","iopub.status.idle":"2021-10-24T10:23:10.145141Z","shell.execute_reply.started":"2021-10-24T10:23:10.140439Z","shell.execute_reply":"2021-10-24T10:23:10.144500Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n                                           batch_size=Batch_size, \n                                           shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n                                          batch_size=Batch_size, \n                                          shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T10:23:10.146593Z","iopub.execute_input":"2021-10-24T10:23:10.146970Z","iopub.status.idle":"2021-10-24T10:23:10.155465Z","shell.execute_reply.started":"2021-10-24T10:23:10.146900Z","shell.execute_reply":"2021-10-24T10:23:10.154789Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs):\n  train_losses = np.zeros(epochs)\n  test_losses = np.zeros(epochs)\n\n  for it in range(epochs):\n    model.train()\n    t0 = datetime.now()\n    train_loss = []\n    for inputs, targets in train_loader:\n      # move data to GPU\n      inputs, targets = inputs.to(device), targets.to(device)\n\n      # zero the parameter gradients\n      optimizer.zero_grad()\n\n      # Forward pass\n      outputs = model(inputs)\n      loss = criterion(outputs, targets)\n        \n      # Backward and optimize\n      loss.backward()\n      optimizer.step()\n\n      train_loss.append(loss.item())\n\n    # Get train loss and test loss\n    train_loss = np.mean(train_loss) # a little misleading\n    \n    model.eval()\n    test_loss = []\n    for inputs, targets in test_loader:\n      inputs, targets = inputs.to(device), targets.to(device)\n      outputs = model(inputs)\n      loss = criterion(outputs, targets)\n      test_loss.append(loss.item())\n    test_loss = np.mean(test_loss)\n\n    # Save losses\n    train_losses[it] = train_loss\n    test_losses[it] = test_loss\n    \n    dt = datetime.now() - t0\n    print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n      Test Loss: {test_loss:.4f}, Duration: {dt}')\n  \n  return train_losses, test_losses","metadata":{"execution":{"iopub.status.busy":"2021-10-24T10:23:10.156426Z","iopub.execute_input":"2021-10-24T10:23:10.158490Z","iopub.status.idle":"2021-10-24T10:23:10.168713Z","shell.execute_reply.started":"2021-10-24T10:23:10.158446Z","shell.execute_reply":"2021-10-24T10:23:10.167927Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_losses, test_losses = batch_gd(\n    model, criterion, optimizer, train_loader, test_loader, epochs=15)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T10:23:10.169993Z","iopub.execute_input":"2021-10-24T10:23:10.170269Z","iopub.status.idle":"2021-10-24T10:25:52.599365Z","shell.execute_reply.started":"2021-10-24T10:23:10.170235Z","shell.execute_reply":"2021-10-24T10:25:52.598628Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_losses, label='train loss')\nplt.plot(test_losses, label='test loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T10:25:52.600740Z","iopub.execute_input":"2021-10-24T10:25:52.601176Z","iopub.status.idle":"2021-10-24T10:25:52.816289Z","shell.execute_reply.started":"2021-10-24T10:25:52.601136Z","shell.execute_reply":"2021-10-24T10:25:52.815398Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model.eval()\nn_correct = 0.\nn_total = 0.\nfor inputs, targets in train_loader:\n  # move data to GPU\n  inputs, targets = inputs.to(device), targets.to(device)\n\n  # Forward pass\n  outputs = model(inputs)\n\n  # Get prediction\n  # torch.max returns both max and argmax\n  _, predictions = torch.max(outputs, 1)\n  \n  # update counts\n  n_correct += (predictions == targets).sum().item()\n  n_total += targets.shape[0]\n\ntrain_acc = n_correct / n_total\n\n\nn_correct = 0.\nn_total = 0.\nfor inputs, targets in test_loader:\n  # move data to GPU\n  inputs, targets = inputs.to(device), targets.to(device)\n\n  # Forward pass\n  outputs = model(inputs)\n\n  # Get prediction\n  # torch.max returns both max and argmax\n  _, predictions = torch.max(outputs, 1)\n  \n  # update counts\n  n_correct += (predictions == targets).sum().item()\n  n_total += targets.shape[0]\n\ntest_acc = n_correct / n_total\nprint(f\"Train acc: {train_acc:.4f}, Test acc: {test_acc:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-24T10:25:52.817630Z","iopub.execute_input":"2021-10-24T10:25:52.818627Z","iopub.status.idle":"2021-10-24T10:26:02.559567Z","shell.execute_reply.started":"2021-10-24T10:25:52.818580Z","shell.execute_reply":"2021-10-24T10:26:02.558816Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
